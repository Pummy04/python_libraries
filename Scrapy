ğŸ“š Scrapy:
Scrapy is an open-source Python framework used for web scraping and web crawling.
It helps you automatically extract data (like texts, images, links, etc.) from websites.

ğŸ”¥ Why Use Scrapy?
Itâ€™s fast and asynchronous (meaning it can handle multiple requests at once).

Supports crawling through multiple pages and websites.

Allows you to save scraped data easily into formats like CSV, JSON, XML, or a database.

Built-in tools to handle requests, responses, parsing, and pipelines.

ğŸ› ï¸ How Scrapy Works (Workflow)
Spider
ğŸ‘‰ The main component where you define what to scrape and from where.
(Example: A spider that visits an e-commerce website and scrapes product names & prices.)

Scheduler
ğŸ‘‰ Organizes and schedules the URLs (pages) to be crawled next.

Downloader
ğŸ‘‰ Sends HTTP requests to the website and gets back the HTML content (response).

Parser (Selectors)
ğŸ‘‰ Extracts the data you want from the HTML using XPath or CSS selectors.

Item Pipeline
ğŸ‘‰ Cleans, processes, and saves the scraped data to files or databases.

ğŸ“¦ Key Components
Component	Role
Spider	Defines the crawling & scraping logic
Item	Structure to hold scraped data
Pipeline	Processes and stores the scraped items
Downloader	Sends requests & receives responses
Middleware	Hooks to process requests/responses

ğŸ” Technologies/Concepts Used
XPath & CSS Selectors â€” to select and extract data.

Asynchronous Requests â€” for faster scraping.

Middlewares â€” to handle cookies, user-agents, proxies, etc.

ğŸ“‚ Scrapy Output Example
JSON

CSV

XML

SQL database (MySQL, PostgreSQL, etc.)

âœ… Real-life Uses of Scrapy
Price comparison websites

Job listing aggregators

News article scrapers

Market research & business intelligence
